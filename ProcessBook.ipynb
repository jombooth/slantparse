{
 "metadata": {
  "name": "",
  "signature": "sha256:072dc7d9de8843c23a415fb23322716ea8368f067715a2a648f606a8c7c55739"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2 align=\"center\">slant parse: <br><br> Using Machine Learning to Determine the Political Leanings of News Publications</h2>\n",
      "\n",
      "<br><center>Serena L Booth, Harvard College, Class of 2016</center>\n",
      "\n",
      "<center>Joseph M Booth, Harvard College, Class of 2015</center>\n",
      "\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 1: Data Collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "import csv\n",
      "from sets import Set\n",
      "from sgmllib import SGMLParser\n",
      "\n",
      "# cite: https://github.com/chungy/diveintopython/blob/master/py/urllister.py\n",
      "class URLLister(SGMLParser):\n",
      "    def reset(self):\n",
      "        SGMLParser.reset(self)\n",
      "        self.urls = []\n",
      "\n",
      "    def start_a(self, attrs):\n",
      "        href = [v for k, v in attrs if k=='href']\n",
      "        if href:\n",
      "            self.urls.extend(href)\n",
      "            \n",
      "def process_url(url):\n",
      "    if str(url)[0] == '/' and str(url).find('2014') != -1: \n",
      "        with open('articles.csv', 'a+') as csvfile:\n",
      "            article_writer = csv.writer(csvfile, delimiter=';')\n",
      "            tmp_url = 'http://www.motherjones.com' + str(url)\n",
      "            usock = urllib.urlopen(tmp_url)\n",
      "            html = usock.read()\n",
      "            title = str(html)[str(html).find('<title>') + len('<title>'):str(html).find('</title>')]\n",
      "            title = title[0: title.find('| Mother')]\n",
      "            content = str(html)[str(html).find('<div id=\"node-header\" class=\"clear-block\">') + len ('<div id=\"node-header\" class=\"clear-block\">'):str(html).find('<div id=\"node-footer\" class=\"clear-block\">')]\n",
      "            \n",
      "            article_writer.writerow(['Mother Jones', 'Lib', title, content])\n",
      "\n",
      "            usock.close()\n",
      "        \n",
      "            \n",
      "\n",
      "def scrape_mother_jones(start_url, iterator, url_list):                \n",
      "    if iterator > 1: \n",
      "        return set()\n",
      "    usock = urllib.urlopen(start_url)\n",
      "    parser = URLLister()\n",
      "    html = usock.read()\n",
      "\n",
      "    parser.feed(html)\n",
      "\n",
      "    usock.close()\n",
      "    parser.close()\n",
      "\n",
      "    url_list = url_list.union(parser.urls)\n",
      "    \n",
      "    for url in url_list: \n",
      "        if str(url)[0] == '/': \n",
      "            tmp_url = 'http://www.motherjones.com' + str(url)\n",
      "            try: \n",
      "                tmp_set = scrape_mother_jones(tmp_url, iterator + 1, url_list)\n",
      "                url_list = url_list.union(tmp_set) \n",
      "            except IOError: \n",
      "                print \"Couldn't Open\"\n",
      "    return url_list\n",
      "\n",
      "        \n",
      "# call the function\n",
      "url_list = set()  \n",
      "url_list = scrape_mother_jones('http://www.motherjones.com/', 1, url_list)\n",
      "\n",
      "print '\\nurls\\n'\n",
      "\n",
      "for url in url_list: \n",
      "    process_url(url)\n",
      "    \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "urls\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}